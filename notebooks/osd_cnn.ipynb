{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "项目：使用轻量级CNN增强短LDPC码的OSD译码性能 (PyTorch版)\n",
    "\n",
    "目标:\n",
    "  验证通过CNN优化OSD中的可靠性排序，可以提升短LDPC码的译码性能。\n",
    "\n",
    "实验流程:\n",
    "  1. 定义LDPC码参数并生成矩阵H和G。\n",
    "  2. 设置计算设备 (自动选择GPU/CUDA或CPU)。\n",
    "  3. 构建并训练一个基于PyTorch的轻量级1D-CNN。\n",
    "  4. 实现三种译码器：\n",
    "     a. 基线NMS译码器\n",
    "     b. NMS + 标准OSD (基于LLR绝对值排序)\n",
    "     c. NMS + CNN增强OSD (基于PyTorch模型输出的错误概率排序)\n",
    "  5. 运行BER仿真，对比三种方案的性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "1. 环境设置与LDPC码生成\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 步骤1: 导入库并生成LDPC码...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--> 步骤1: 导入库并生成LDPC码...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "print(\"--> 步骤1: 导入库并生成LDPC码...\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pyldpc import make_ldpc, decode, get_message, encode\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# --- LDPC码参数定义 ---\n",
    "n = 128\n",
    "d_v = 4\n",
    "d_c = 8\n",
    "seed = np.random.RandomState(42)\n",
    "\n",
    "H, G = make_ldpc(n, d_v, d_c, seed=seed, systematic=True, sparse=True)\n",
    "n_code, k_info = G.shape\n",
    "\n",
    "print(f\"    实际LDPC码参数: n={n_code}, k={k_info}, 码率={k_info/n_code:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "2. 设置计算设备 (GPU/CPU)\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤2: 检测并设置计算设备...\")\n",
    "# 检查是否有可用的CUDA GPU，如果有则使用，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"    将使用设备: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "3. 为CNN生成训练数据\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤3: 为CNN生成训练数据...\")\n",
    "\n",
    "def generate_training_data(n_samples, snr_db):\n",
    "    print(f\"    正在生成 {n_samples} 条训练样本，信噪比SNR = {snr_db} dB...\")\n",
    "    v_messages = np.zeros((k_info, n_samples))\n",
    "    c_codewords_modulated = encode(G, v_messages, snr_db, seed=seed)\n",
    "\n",
    "    sigma2 = 10**(-snr_db / 10)\n",
    "    mean_llr = 2 / sigma2\n",
    "    std_llr = np.sqrt(4 / sigma2)\n",
    "    y_noisy_llrs = np.random.normal(loc=mean_llr, scale=std_llr, size=c_codewords_modulated.shape)\n",
    "\n",
    "    y_labels = (y_noisy_llrs < 0).astype(int)\n",
    "\n",
    "    # PyTorch的Conv1d需要 (N, C, L) 格式, 即 (批次数, 通道数, 长度)\n",
    "    # 我们的通道数是1\n",
    "    X_train = y_noisy_llrs.T.reshape((n_samples, 1, n_code))\n",
    "    y_train = y_labels.T.reshape((n_samples, 1, n_code))\n",
    "\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "4. 构建并训练CNN模型\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤4: 构建并训练PyTorch CNN模型...\")\n",
    "\n",
    "# --- a. 定义PyTorch模型 ---\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, input_len):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=1, kernel_size=3, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "5. 实现三种译码器\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤5: 实现三种不同的译码器...\")\n",
    "\n",
    "def is_valid_codeword(H, c: np.ndarray) -> bool:\n",
    "    if c is None: return False\n",
    "    return np.all((H.dot(c) % 2) == 0)\n",
    "\n",
    "def osd_rescue(H, base_decision: np.ndarray, reliability_vector: np.ndarray, L: int = 15):\n",
    "    idx_sorted_by_reliability = np.argsort(reliability_vector)\n",
    "    least_reliable_indices = idx_sorted_by_reliability[:min(L, len(idx_sorted_by_reliability))]\n",
    "\n",
    "    for i in least_reliable_indices:\n",
    "        candidate = base_decision.copy(); candidate[i] ^= 1\n",
    "        if is_valid_codeword(H, candidate): return candidate\n",
    "\n",
    "    for i in range(len(least_reliable_indices)):\n",
    "        for j in range(i + 1, len(least_reliable_indices)):\n",
    "            idx1, idx2 = least_reliable_indices[i], least_reliable_indices[j]\n",
    "            candidate = base_decision.copy(); candidate[idx1] ^= 1; candidate[idx2] ^= 1\n",
    "            if is_valid_codeword(H, candidate): return candidate\n",
    "    return base_decision\n",
    "\n",
    "def standard_osd_decoder(H, y_channel: np.ndarray, snr: float) -> np.ndarray:\n",
    "    decoded_word = decode(H, y_channel, snr, maxiter=100)\n",
    "    if is_valid_codeword(H, decoded_word): return decoded_word\n",
    "    channel_reliability = np.abs(y_channel)\n",
    "    return osd_rescue(H, decoded_word, channel_reliability, L=15)\n",
    "\n",
    "def cnn_enhanced_decoder(H, y_channel: np.ndarray, snr: float, model, device) -> np.ndarray:\n",
    "    decoded_word = decode(H, y_channel, snr, maxiter=100)\n",
    "    if is_valid_codeword(H, decoded_word): return decoded_word\n",
    "\n",
    "    # --- PyTorch预测过程 ---\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    with torch.no_grad(): # 关闭梯度计算，加速预测\n",
    "        # 1. Numpy -> PyTorch Tensor\n",
    "        y_tensor = torch.from_numpy(y_channel).float()\n",
    "        # 2. Reshape for Conv1d: (L) -> (N, C, L) = (1, 1, n_code)\n",
    "        y_tensor = y_tensor.reshape((1, 1, n_code))\n",
    "        # 3. Move to device\n",
    "        y_tensor = y_tensor.to(device)\n",
    "        # 4. Predict\n",
    "        cnn_output_tensor = model(y_tensor)\n",
    "        # 5. Move back to CPU and convert to Numpy\n",
    "        cnn_error_probability = cnn_output_tensor.cpu().numpy().flatten()\n",
    "\n",
    "    # CNN输出的是“错误概率”，概率越高，比特越不可靠。\n",
    "    # 我们约定osd_rescue中，值越小越不可靠，所以传入1.0 - 概率\n",
    "    cnn_reliability = 1.0 - cnn_error_probability\n",
    "    return osd_rescue(H, decoded_word, cnn_reliability, L=15)\n",
    "\n",
    "print(\"    译码器实现完毕。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "6. 运行BER性能仿真\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤6: 开始最终的BER性能仿真...\")\n",
    "snrs_db = np.arange(1.0, 4.5, 0.5)\n",
    "n_trials = 2000\n",
    "max_bp_iter = 100\n",
    "\n",
    "ber_baseline, ber_std_osd, ber_cnn_osd = [], [], []\n",
    "\n",
    "for snr in snrs_db:\n",
    "    start_time = time.time()\n",
    "    errors_baseline, errors_std_osd, errors_cnn_osd = 0, 0, 0\n",
    "\n",
    "    v_messages = np.random.randint(2, size=(k_info, n_trials))\n",
    "    y_noisy = encode(G, v_messages, snr, seed=seed)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        y_col, v_col = y_noisy[:, i], v_messages[:, i]\n",
    "        d_base = decode(H, y_col, snr, maxiter=max_bp_iter)\n",
    "        errors_baseline += np.count_nonzero(get_message(G, d_base) != v_col)\n",
    "        d_std_osd = standard_osd_decoder(H, y_col, snr)\n",
    "        errors_std_osd += np.count_nonzero(get_message(G, d_std_osd) != v_col)\n",
    "        # 在调用时传入模型和设备\n",
    "        d_cnn_osd = cnn_enhanced_decoder(H, y_col, snr, cnn_model, device)\n",
    "        errors_cnn_osd += np.count_nonzero(get_message(G, d_cnn_osd) != v_col)\n",
    "\n",
    "    ber_baseline.append(errors_baseline / (k_info * n_trials))\n",
    "    ber_std_osd.append(errors_std_osd / (k_info * n_trials))\n",
    "    ber_cnn_osd.append(errors_cnn_osd / (k_info * n_trials))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"    SNR={snr:.2f} dB 在 {end_time - start_time:.1f}s 内完成. BERs: \")\n",
    "    print(f\"      - Baseline:  {ber_baseline[-1]:.6f}\")\n",
    "    print(f\"      - Std OSD:   {ber_std_osd[-1]:.6f}\")\n",
    "    print(f\"      - CNN OSD:   {ber_cnn_osd[-1]:.6f}\")\n",
    "\n",
    "print(\"    仿真完成。\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "7. 结果可视化与分析\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--> 步骤7: 绘制性能对比图...\")\n",
    "# 设置matplotlib支持中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.semilogy(snrs_db, ber_baseline, 'o:', label='基线NMS译码器', color='gray', markersize=8)\n",
    "plt.semilogy(snrs_db, ber_std_osd, 's--', label='NMS + 标准OSD (基于LLR)', color='indianred', markersize=8)\n",
    "plt.semilogy(snrs_db, ber_cnn_osd, '^-', label='NMS + CNN增强OSD (PyTorch版)', color='royalblue', markersize=8)\n",
    "\n",
    "plt.title(f'({n_code}, {k_info}) LDPC码不同译码方案性能对比', fontsize=16)\n",
    "plt.xlabel('信噪比 SNR (dB)', fontsize=12)\n",
    "plt.ylabel('误比特率 BER', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.ylim(1e-5, 1)\n",
    "plt.show()\n",
    "\n",
    "print(\"--> 脚本执行完毕。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
